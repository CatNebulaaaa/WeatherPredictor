# 基于 ConvLSTM U-Net 的短时强降水预测

模型以unet为backbone，采用了 **ConvLSTM U-Net** 架构,文件包括了原始数据处理、Dataset以及dataloader定义、模型定义，模型训练

## 文件结构

```
.
├── model.py                # 定义 ConvLSTM U-Net 模型架构
├── dataset.py              # PyTorch 数据集和数据加载器实现
├── preproc.py              # 原始数据预处理脚本
├── training.py             # 模型训练、验证和测试的主脚本
├── params.json             # 存储所有路径和超参数的配置文件
│
├── data/
│   ├── raw_dataset/        # 存放原始数据 (需按特定结构组织)
│   └── processed_data/     # 存放预处理后生成的 Zarr 数据集
│       ├── train/
│       ├── val/
│       └── test/
│
└── README.md               # 本说明文件
```

## 工作流与文件说明


### 1. `params.json` - 参数/路径配置文件
一个 JSON 文件，用于统一管理所有路径、数据规格和训练超参数。

### 2. `preproc.py` - 数据预处理
负责将分散、原始的 `.npy` 数据文件转换为模型可以直接训练的格式。
*   **原理：**
    1.  从 `params.json` 读取数据路径和特征列表。
    2.  以**事件（Case）**为单位遍历所有原始数据。
    3.  对每个事件，将不同来源（雷达、NWP、标签）的数据在时间轴上对齐，并使用 `np.nan` 填充缺失的时间步。
    4.  对每个事件数据进行**时间插值**，以处理 `nan` 值。
    5.  将所有事件路径随机划分为训练集、验证集和测试集。
    6.  **仅使用训练集**的所有数据来计算标准化的统计参数（min/max值），以防止数据泄漏。
    7.  最后，再次遍历所有事件，应用这些统计参数进行标准化，并将每个处理好的事件保存为一个独立的 `.zarr` 文件，存放在 `processed_data/` 下对应的 `train/`, `val/`, `test/` 目录中。

### 3. `dataset.py` - 数据加载
该文件定义了 `ZarrPatchDataset` 类，继承自 `torch.utils.data.Dataset`。
*   **原理：**
    1.  初始化时，它会扫描指定目录（如 `processed_data/train`）下的所有 `.zarr` 事件文件。
    2.  它会创建一个**样本映射表 (`sample_map`)**，该表记录了全局索引如何对应到具体的某个事件文件的某个时间步，而无需将数据全部加载到内存。
    3.  当训练时调用 `__getitem__` 时，它会：
        *   根据索引找到对应的 `.zarr` 文件和时间切片。
        *   从该事件的完整空间网格中**随机裁剪（Random Crop）**出一个小的图块（Patch）。这既解决了显存限制问题，也起到了数据增强的作用。
        *   从磁盘读取这个小图块的数据，拼接成模型的输入张量 `x` 和目标张量 `y`。

### 4. `model.py` - 模型架构
定义了核心的 `ConvLSTM_UNet` 模型。
*   **原理：**
    *   模型采用 **U-Net** 编码器-解码器结构，善于捕捉空间特征。
    *   编码器的每个下采样模块中，标准的卷积层被替换为 **ConvLSTM** 模块。这使得模型不仅能学习每一帧图像的空间特征，还能捕捉特征在时间序列上的演化规律。
    *   解码器使用 Skip-Connections 来融合浅层和深层的特征，以生成高分辨率的预测结果。

### 5. `training.py` - 训练与评估流程
这是驱动整个模型训练过程的主脚本。
*   **原理：**
    1.  从 `params.json` 加载所有训练相关的配置。
    2.  调用 `dataset.py` 中的 `load_datasets` 函数来创建训练、验证和测试的数据加载器 (`DataLoader`)。
    3.  初始化 `ConvLSTM_UNet` 模型、损失函数（MSE）、优化器（AdamW）以及学习率调度器（ReduceLROnPlateau）。
    4.  进入主训练循环：
        *   在每个 Epoch 中，执行训练和验证，预测两小时后的降水。
        *   根据验证集损失自动调整学习率。
        *   如果当前模型在验证集上表现最好，则将其权重保存到 `params.json` 中指定的路径。
    5.  训练结束后，加载性能最佳的模型，并在测试集上进行最终评估。
    6.  暂时只使用了MSE损失函数重加权来缓解长尾问题，有待后续改进